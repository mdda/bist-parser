Scene Graph Parsing as Dependency Parsing
=========================================================

This repository contains code for Scene Graph Parsing as Dependency Parsing, NAACL 2018.

>    And this **fork** of the repo does the preprocessing steps much more efficiently, 
>    since parsing streaming ```json``` is *way* more efficient than manipulating the visual genome
>    files in 10 sections, and stitching them back together...
>
>    It also makes the code Python 2/3 compatible.


If you use the code, please cite 
``` 
@inproceedings{wang2018sgparser,     
  title={Scene Graph Parsing as Dependency Parsing},  
  author={Wang, Yu-Siang and Liu, Chenxi and Zeng, Xiaohui and Yuille, Alan},  
  booktitle={NAACL},  
  year={2018}
} 
```


## Requirements
- python 2.7 or 3.5+
- PyTorch v0.3 or higher

## Files
./model
- include training codes

./preprocess
- include mapping from json data to conll file 

<strike>
./coco-caption
- evaluate coco caption with dependency sg parser
</strike>

## Customized Dependency Scene Graph Parser

#### Data Split

For training (development) data, we adopt the overlap images between Visual Genome training (development) dataset and MSCOCO training (development) dataset.


#### Preprocessing ####

<strike>
1. OLD : Split the Visual Genome {image_data.json, region_graphs.json, attributes.json} files each into 10 pieces, and name these files ```x_%num.json```, 
   where x={image_data, all_region_graphs, all_attributes} and num={0..9}. 
   (The size for the every first 9 pieces is all_region_graph.size()/10) and put them into ```preprocess/data```
   The reason to split to 10 pieces is for acclerating the preprocessing speed. 
</strike>  


1. Row-ize the original Visual Genome files : 

```
cat image_data.json    | jq -n --compact-output --stream 'fromstream(1|truncate_stream(inputs))' > image_data.json.rows
cat attributes.json    | jq -n --compact-output --stream 'fromstream(1|truncate_stream(inputs))' > attributes.json.rows
cat region_graphs.json | jq -n --compact-output --stream 'fromstream(1|truncate_stream(inputs))' > region_graphs.json.rows
```


2. Move the ```.json.rows``` files into ```./preprocess/data/``` (or symlink the ```./preprocess/data``` directory to the folder with the downloaded / preprocessed data).

3. CHECK : Set ```nltk``` wordnet path in line ~10 in ```data_to_conll.py```


<strike>
Now run :
```
bash ./preprocess.sh 
# ...
python split_preprocess.py NUM TARGET
```

where NUM={0..9}, TARGET={coco_train, coco_dev}, which means there are total 20 commands to run.
We strongly suggest you to open multiple terminals to execute above commands to fasten the preprocesseing time.
</strike>


Now run the following, which creates the files ```./intermediate/pre_coco_train.json.rows``` and ```./intermediate/pre_coco_dev.json.rows``` :
```
python split_preprocess.py 0000 coco_train
python split_preprocess.py 0000 coco_dev
```

Finally, run the following to convert (via the paper's Algorithm 1) ```./intermediate/pre_coco_XXX.json.rows``` to ```./output/coco_XXX.conll``` :

```
python data_to_conll.py --input ./output/pre_coco_train.json.rows --output ./output/coco_train.conll --train  # i.e. this is for training
python data_to_conll.py --input ./output/pre_coco_dev.json.rows   --output ./output/coco_dev.conll            # No '--train' : Don't skip anything

## Parameters :
# --input:  processed data generated by split.py
# --output: desired output
# --train : determine whether the file is used for training or not (True if present, False if absent)
```

This compeletes the preprocessing required.


#### Prove Oracle numbers ...

```
cd ../model/src/utils/evaluation_script/

. ~/env3/bin/activate   # Evaluation code updated to be 2/3 compatible
bash eval.sh  # -> python spice_eval.py
```



#### Training

```
cd ./model/
bash run.sh
```

In run.sh, you can set the paramters
```
time CUDA_VISIBLE_DEVICES=2 python src/parser.py --outdir ./output --train ./output/coco_train.conll --dev /output/coco_dev.conll \
                                                 --epochs 30 --lstmdims 256 --lstmlayers 2  --k 3 --usehead --userl
```
Please ignore .txt files which are useless

#### Validation

```
cd ./model/src/utils/evaluation_script/
bash eval.sh
```
In eval.sh, pre_coco_dev.json is the ground truth file.

```
time python spice_eval.py pre_coco_dev.json output/predict_coco.conll
```
Remember to set nltk_wordnet path in `./model/src/utils/evaluation_script/spice_eval.py` to use wordnet for spice metric


#### Testing

```
python src/parser.py --predict --outdir [results directory] --test test.conll [--extrn extrn.vectors] --model [trained model file] --params [param file generate during training]
```
